{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from medpy import metric\n",
    "\n",
    "\n",
    "def assert_shape(test, reference):\n",
    "\n",
    "    assert test.shape == reference.shape, \"Shape mismatch: {} and {}\".format(\n",
    "        test.shape, reference.shape)\n",
    "\n",
    "\n",
    "class ConfusionMatrix:\n",
    "\n",
    "    def __init__(self, test=None, reference=None):\n",
    "\n",
    "        self.tp = None\n",
    "        self.fp = None\n",
    "        self.tn = None\n",
    "        self.fn = None\n",
    "        self.size = None\n",
    "        self.reference_empty = None\n",
    "        self.reference_full = None\n",
    "        self.test_empty = None\n",
    "        self.test_full = None\n",
    "        self.set_reference(reference)\n",
    "        self.set_test(test)\n",
    "\n",
    "    def set_test(self, test):\n",
    "\n",
    "        self.test = test\n",
    "        self.reset()\n",
    "\n",
    "    def set_reference(self, reference):\n",
    "\n",
    "        self.reference = reference\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.tp = None\n",
    "        self.fp = None\n",
    "        self.tn = None\n",
    "        self.fn = None\n",
    "        self.size = None\n",
    "        self.test_empty = None\n",
    "        self.test_full = None\n",
    "        self.reference_empty = None\n",
    "        self.reference_full = None\n",
    "\n",
    "    def compute(self):\n",
    "\n",
    "        if self.test is None or self.reference is None:\n",
    "            raise ValueError(\"'test' and 'reference' must both be set to compute confusion matrix.\")\n",
    "\n",
    "        assert_shape(self.test, self.reference)\n",
    "\n",
    "        self.tp = int(((self.test != 0) * (self.reference != 0)).sum())\n",
    "        self.fp = int(((self.test != 0) * (self.reference == 0)).sum())\n",
    "        self.tn = int(((self.test == 0) * (self.reference == 0)).sum())\n",
    "        self.fn = int(((self.test == 0) * (self.reference != 0)).sum())\n",
    "        self.size = int(np.prod(self.reference.shape, dtype=np.int64))\n",
    "        self.test_empty = not np.any(self.test)\n",
    "        self.test_full = np.all(self.test)\n",
    "        self.reference_empty = not np.any(self.reference)\n",
    "        self.reference_full = np.all(self.reference)\n",
    "\n",
    "    def get_matrix(self):\n",
    "\n",
    "        for entry in (self.tp, self.fp, self.tn, self.fn):\n",
    "            if entry is None:\n",
    "                self.compute()\n",
    "                break\n",
    "\n",
    "        return self.tp, self.fp, self.tn, self.fn\n",
    "\n",
    "    def get_size(self):\n",
    "\n",
    "        if self.size is None:\n",
    "            self.compute()\n",
    "        return self.size\n",
    "\n",
    "    def get_existence(self):\n",
    "\n",
    "        for case in (self.test_empty, self.test_full, self.reference_empty, self.reference_full):\n",
    "            if case is None:\n",
    "                self.compute()\n",
    "                break\n",
    "\n",
    "        return self.test_empty, self.test_full, self.reference_empty, self.reference_full\n",
    "\n",
    "\n",
    "def dice(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"2TP / (2TP + FP + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty and reference_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(2 * tp / (2 * tp + fp + fn))\n",
    "\n",
    "\n",
    "def jaccard(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TP / (TP + FP + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty and reference_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(tp / (tp + fp + fn))\n",
    "\n",
    "\n",
    "def precision(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TP / (TP + FP)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    return float(tp / (tp + fp))\n",
    "\n",
    "\n",
    "def sensitivity(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TP / (TP + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if reference_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(tp / (tp + fn))\n",
    "\n",
    "\n",
    "def recall(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TP / (TP + FN)\"\"\"\n",
    "\n",
    "    return sensitivity(test, reference, confusion_matrix, nan_for_nonexisting, **kwargs)\n",
    "\n",
    "\n",
    "def specificity(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TN / (TN + FP)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(tn / (tn + fp))\n",
    "\n",
    "\n",
    "def accuracy(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"(TP + TN) / (TP + FP + FN + TN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return float((tp + tn) / (tp + fp + tn + fn))\n",
    "\n",
    "\n",
    "def fscore(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, beta=1., **kwargs):\n",
    "    \"\"\"(1 + b^2) * TP / ((1 + b^2) * TP + b^2 * FN + FP)\"\"\"\n",
    "\n",
    "    precision_ = precision(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "    recall_ = recall(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "    return (1 + beta*beta) * precision_ * recall_ /\\\n",
    "        ((beta*beta * precision_) + recall_)\n",
    "\n",
    "\n",
    "def false_positive_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"FP / (FP + TN)\"\"\"\n",
    "\n",
    "    return 1 - specificity(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def false_omission_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"FN / (TN + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(fn / (fn + tn))\n",
    "\n",
    "\n",
    "def false_negative_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"FN / (TP + FN)\"\"\"\n",
    "\n",
    "    return 1 - sensitivity(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def true_negative_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TN / (TN + FP)\"\"\"\n",
    "\n",
    "    return specificity(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def false_discovery_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"FP / (TP + FP)\"\"\"\n",
    "\n",
    "    return 1 - precision(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def negative_predictive_value(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TN / (TN + FN)\"\"\"\n",
    "\n",
    "    return 1 - false_omission_rate(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def total_positives_test(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"TP + FP\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return tp + fp\n",
    "\n",
    "\n",
    "def total_negatives_test(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"TN + FN\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return tn + fn\n",
    "\n",
    "\n",
    "def total_positives_reference(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"TP + FN\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return tp + fn\n",
    "\n",
    "\n",
    "def total_negatives_reference(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"TN + FP\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return tn + fp\n",
    "\n",
    "\n",
    "def hausdorff_distance(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, voxel_spacing=None, connectivity=1, **kwargs):\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty or test_full or reference_empty or reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test, reference = confusion_matrix.test, confusion_matrix.reference\n",
    "\n",
    "    return metric.hd(test, reference, voxel_spacing, connectivity)\n",
    "\n",
    "\n",
    "def hausdorff_distance_95(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, voxel_spacing=None, connectivity=1, **kwargs):\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty or test_full or reference_empty or reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test, reference = confusion_matrix.test, confusion_matrix.reference\n",
    "\n",
    "    return metric.hd95(test, reference, voxel_spacing, connectivity)\n",
    "\n",
    "\n",
    "def avg_surface_distance(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, voxel_spacing=None, connectivity=1, **kwargs):\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty or test_full or reference_empty or reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test, reference = confusion_matrix.test, confusion_matrix.reference\n",
    "\n",
    "    return metric.asd(test, reference, voxel_spacing, connectivity)\n",
    "\n",
    "\n",
    "def avg_surface_distance_symmetric(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, voxel_spacing=None, connectivity=1, **kwargs):\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty or test_full or reference_empty or reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test, reference = confusion_matrix.test, confusion_matrix.reference\n",
    "\n",
    "    return metric.assd(test, reference, voxel_spacing, connectivity)\n",
    "\n",
    "\n",
    "ALL_METRICS = {\n",
    "    \"False Positive Rate\": false_positive_rate,\n",
    "    \"Dice\": dice,\n",
    "    \"Jaccard\": jaccard,\n",
    "    \"Hausdorff Distance\": hausdorff_distance,\n",
    "    \"Hausdorff Distance 95\": hausdorff_distance_95,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"Avg. Symmetric Surface Distance\": avg_surface_distance_symmetric,\n",
    "    \"Avg. Surface Distance\": avg_surface_distance,\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"False Omission Rate\": false_omission_rate,\n",
    "    \"Negative Predictive Value\": negative_predictive_value,\n",
    "    \"False Negative Rate\": false_negative_rate,\n",
    "    \"True Negative Rate\": true_negative_rate,\n",
    "    \"False Discovery Rate\": false_discovery_rate,\n",
    "    \"Total Positives Test\": total_positives_test,\n",
    "    \"Total Negatives Test\": total_negatives_test,\n",
    "    \"Total Positives Reference\": total_positives_reference,\n",
    "    \"total Negatives Reference\": total_negatives_reference\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "7.0\n",
      "14.798648586948742\n",
      "3.605551275463989\n",
      "5.830951894845301\n",
      "4.242640687119285\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import torch\n",
    "import argparse\n",
    "import skimage, os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import nibabel as nib\n",
    "import csv\n",
    "\n",
    "BASE_IMG_PATH=os.path.join('/','home','asma','Documents','GPU','final_results01','Task02_Heart','Task02_Heart')\n",
    "gt=sorted(glob(os.path.join(BASE_IMG_PATH,'gt_3dsrn3','*.nii')))\n",
    "out=sorted(glob(os.path.join(BASE_IMG_PATH,'resnnUNet_seg_output3','*.nii')))\n",
    "\n",
    "f_metrics = [\n",
    "        \"False Positive Rate\",\n",
    "        \"Dice\",\n",
    "        \"Jaccard\",\n",
    "        \"Hausdorff Distance\",\n",
    "        \"Hausdorff Distance 95\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"Avg. Symmetric Surface Distance\",\n",
    "        \"Avg. Surface Distance\",\n",
    "        \"Accuracy\",\n",
    "        \"False Omission Rate\",\n",
    "        \"Negative Predictive Value\",\n",
    "        \"False Negative Rate\",\n",
    "        \"True Negative Rate\",\n",
    "        \"False Discovery Rate\",\n",
    "        \"Total Positives Test\",\n",
    "        \"Total Negatives Test\",\n",
    "        \"Total Positives Reference\",\n",
    "        \"total Negatives Reference\"]\n",
    "with open(os.path.join(BASE_IMG_PATH,'my_metrics_3DSRNet_test3.csv'), 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(f_metrics)\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for i in range(len(gt)):\n",
    "        test = nib.load(out[i]).get_fdata()\n",
    "        reference = nib.load(gt[i]).get_fdata()\n",
    "        test = np.atleast_1d(test.astype(np.bool))\n",
    "        reference = np.atleast_1d(reference.astype(np.bool))\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "        tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    \n",
    "        my_metrics = {\n",
    "            false_positive_rate(test, reference,confusion_matrix),\n",
    "            dice(test, reference,confusion_matrix),\n",
    "            jaccard(test, reference,confusion_matrix),\n",
    "            hausdorff_distance(test, reference,confusion_matrix),\n",
    "            hausdorff_distance_95(test, reference,confusion_matrix),\n",
    "            precision(test, reference,confusion_matrix),\n",
    "            recall(test, reference,confusion_matrix),\n",
    "            avg_surface_distance_symmetric(test, reference,confusion_matrix),\n",
    "            avg_surface_distance(test, reference,confusion_matrix),\n",
    "            accuracy(test, reference,confusion_matrix),\n",
    "            false_omission_rate(test, reference,confusion_matrix),\n",
    "            negative_predictive_value(test, reference,confusion_matrix),\n",
    "            false_negative_rate(test, reference,confusion_matrix),\n",
    "            true_negative_rate(test, reference,confusion_matrix),\n",
    "            false_discovery_rate(test, reference,confusion_matrix),\n",
    "            total_positives_test(test, reference,confusion_matrix),\n",
    "            total_negatives_test(test, reference,confusion_matrix),\n",
    "            total_positives_reference(test, reference,confusion_matrix),\n",
    "            total_negatives_reference(test, reference,confusion_matrix)\n",
    "            }\n",
    "        writer.writerow(my_metrics)\n",
    "#        writer.writerow({tp,fp,tn,fn})\n",
    "        prec = float(tp / (tp + fn))\n",
    "        rec = float(tp / (tp + fp))\n",
    "        writer.writerow({prec,rec})\n",
    "#        print(metric.binary.hd(test, reference))\n",
    "        \n",
    "#    metrics = np.hstack((metrics,my_metrics))\n",
    "\n",
    "#    print(confusion_matrix.get_matrix())\n",
    "#    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "#    print(float(tp / (tp + fn)))\n",
    "        print(metric.hd95(test,reference))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22253\n",
      "11128392\n",
      "601\n",
      "10354\n"
     ]
    }
   ],
   "source": [
    "tp = ((test != 0) * (reference != 0)).sum()\n",
    "tn = ((test == 0) * (reference == 0)).sum()\n",
    "fp = ((test != 0) * (reference == 0)).sum()\n",
    "fn = ((test == 0) * (reference != 0)).sum()\n",
    "\n",
    "print(tp)\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0.002147686882388311, 0.6909669804847254, 0.5278453409376834, 0.534355033856212, 0.0, 2.598223623397627, 2.9179019091403826, 7.0, 0.9978009765625, 0.9999429994773807, 0.022558726460881418, 11.445523142259598, 47111, 10214245, 0.46564496614378803, 5.7000522619249556e-05, 0.9978523131176117, 25755, 10192889}\n",
      " {0.0021754115045494737, 0.7383928221604044, 0.5852795031055901, 0.5858131631299734, 0.0, 3.0114992784993113, 3.3880742187589323, 7.0, 0.9978264973958333, 0.9999952005640647, 0.0015540564405043256, 48256, 9167744, 9187687, 15.297058540778355, 28313, 0.9978245884954505, 4.799435935383885e-06, 0.41418683687002655}\n",
      " {0.0030679614539380617, 0.5901727931243004, 0.4186135650142367, 0.4225391035206986, 0.0, 5.588831503392134, 0.99688935546875, 7.783421062628765, 0.9999500280834317, 0.02171131206278787, 0.5774608964793013, 54279, 10216556, 14.798648586948742, 113.81124724736128, 23444, 0.9969320385460619, 4.997191656830184e-05, 10185721}\n",
      " {0.0009734641830030366, 0.8037828421090056, 0.671937228793913, 3.605551275463989, 0.6738398259366338, 0.0, 1.9380045942879218, 2.1908872464434572, 0.9990200639204545, 0.9999915408546889, 0.0041844690129058115, 14.89966442575134, 33551, 22703, 0.999026535816997, 0.32616017406336617, 11230449, 11241297, 8.459145311109111e-06}\n",
      " {0.0014014992874139542, 0.7770639345654204, 0.6354084702615136, 0.6354967132672901, 0.0, 5.830951894845301, 2.3458997230507785, 2.584368022456068, 0.9986013849431818, 9.433981132056603, 5.347214226156505e-07, 0.9999994652785774, 0.998598500712586, 43204, 27462, 0.00021848372296262575, 0.36450328673270993, 11236538, 11220796}\n",
      " {0.000929548083778875, 0.8024738104253439, 0.6701096121416527, 0.6824608212960407, 4.242640687119285, 0.0, 1.699398725235165, 1.9001880923892505, 0.999018509891055, 9.273618495495704, 0.9999459969109514, 0.9990704519162211, 0.3175391787039593, 11128993, 22854, 5.400308904857789e-05, 0.02629736588780962, 11138746, 32607}]\n"
     ]
    }
   ],
   "source": [
    "#my_metrics = {\n",
    "#        \"False Positive Rate\": false_positive_rate(test, reference),\n",
    "#        \"Dice\": dice(test, reference),\n",
    "#        \"Jaccard\": jaccard(test, reference),\n",
    "#        \"Hausdorff Distance\": hausdorff_distance(test, reference),\n",
    "#        \"Hausdorff Distance 95\": hausdorff_distance_95(test, reference),\n",
    "#        \"Precision\": precision(test, reference),\n",
    "#        \"Recall\": recall(test, reference),\n",
    "#        \"Avg. Symmetric Surface Distance\": avg_surface_distance_symmetric(test, reference),\n",
    "#        \"Avg. Surface Distance\": avg_surface_distance(test, reference),\n",
    "#        \"Accuracy\": accuracy(test, reference),\n",
    "#        \"False Omission Rate\": false_omission_rate(test, reference),\n",
    "#        \"Negative Predictive Value\": negative_predictive_value(test, reference),\n",
    "#        \"False Negative Rate\": false_negative_rate(test, reference),\n",
    "#        \"True Negative Rate\": true_negative_rate(test, reference),\n",
    "#        \"False Discovery Rate\": false_discovery_rate(test, reference),\n",
    "#        \"Total Positives Test\": total_positives_test(test, reference),\n",
    "#        \"Total Negatives Test\": total_negatives_test(test, reference),\n",
    "#        \"Total Positives Reference\": total_positives_reference(test, reference),\n",
    "#        \"total Negatives Reference\": total_negatives_reference(test, reference)\n",
    "#    } \n",
    "#my_metrics = np.array(my_metrics)\n",
    "#metrics = np.array([\n",
    "#        \"False Positive Rate\",\"Dice\",\n",
    "#        \"Jaccard\",\n",
    "#        \"Hausdorff Distance\",\n",
    "#        \"Hausdorff Distance 95\",\n",
    "#        \"Precision\",\n",
    "#        \"Recall\",\n",
    "#        \"Avg. Symmetric Surface Distance\",\n",
    "#        \"Avg. Surface Distance\",\n",
    "#        \"Accuracy\",\n",
    "#        \"False Omission Rate\",\n",
    "#        \"Negative Predictive Value\",\n",
    "#        \"False Negative Rate\",\n",
    "#        \"True Negative Rate\",\n",
    "#        \"False Discovery Rate\",\n",
    "#        \"Total Positives Test\",\n",
    "#        \"Total Negatives Test\",\n",
    "#        \"Total Positives Reference\",\n",
    "#        \"total Negatives Reference\"])    \n",
    "\n",
    "#f_metrics = np.hstack((my_metrics,metrics))\n",
    "\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  --------  --------  --------  --------  --------  --------  -------  --------  ---------  -----------  ------------  ---------------  ---------------  ------------  ---------------  -----------  ---------------  ---------------\n",
      "0.00214769   0.690967  0.527845  0.534355  0.977441  2.59822   2.9179    7        0.997801  0.999943   0.0225587       11.4455    47111                1.02142e+07      0.465645      5.70005e-05  0.997852     25755                1.01929e+07\n",
      "0.00217541   0.738393  0.58528   0.585813  0.998446  3.0115    3.38807   7        0.997826  0.999995   0.00155406   48256             9.16774e+06      9.18769e+06     15.2971    28313            0.997825         4.79944e-06      0.414187\n",
      "0.00306796   0.590173  0.418614  0.422539  0.978289  5.58883   0.996889  7.78342  0.99995   0.0217113  0.577461     54279             1.02166e+07     14.7986         113.811     23444            0.996932         4.99719e-05      1.01857e+07\n",
      "0.000973464  0.803783  0.671937  3.60555   0.67384   0.995816  1.938     2.19089  0.99902   0.999992   0.00418447      14.8997    33551            22703                0.999027      0.32616      1.12304e+07      1.12413e+07      8.45915e-06\n",
      "0.0014015    0.777064  0.635408  0.635497  0.999782  5.83095   2.3459    2.58437  0.998601  9.43398    5.34721e-07      0.999999      0.998599     43204            27462             0.000218484  0.364503         1.12365e+07      1.12208e+07\n",
      "0.000929548  0.802474  0.67011   0.682461  4.24264   0.973703  1.6994    1.90019  0.999019  9.27362    0.999946         0.99907       0.317539         1.1129e+07   22854             5.40031e-05  0.0262974        1.11387e+07  32607\n",
      "-----------  --------  --------  --------  --------  --------  --------  -------  --------  ---------  -----------  ------------  ---------------  ---------------  ------------  ---------------  -----------  ---------------  ---------------\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "f_metrics = [\n",
    "        \"False Positive Rate\",\"Dice\",\n",
    "        \"Jaccard\",\n",
    "        \"Hausdorff Distance\",\n",
    "        \"Hausdorff Distance 95\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"Avg. Symmetric Surface Distance\",\n",
    "        \"Avg. Surface Distance\",\n",
    "        \"Accuracy\",\n",
    "        \"False Omission Rate\",\n",
    "        \"Negative Predictive Value\",\n",
    "        \"False Negative Rate\",\n",
    "        \"True Negative Rate\",\n",
    "        \"False Discovery Rate\",\n",
    "        \"Total Positives Test\",\n",
    "        \"Total Negatives Test\",\n",
    "        \"Total Positives Reference\",\n",
    "        \"total Negatives Reference\"]\n",
    "with open(os.path.join(BASE_IMG_PATH,'my_metrics_3DSRNet_test1.csv'), 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(f_metrics)\n",
    "    writer.writerows(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "critical_value_dict = {70:1.04, 75:1.15, 80:1.28, 85:1.44, 90:1.64 , 95:1.96 , 98:2.33 , 99:2.58}\n",
    "\n",
    "def odds_ratio(a, b, c, d):\n",
    "    if a==0 or np.isnan(a) or b==0 or np.isnan(b) or c==0 or np.isnan(c) or d==0 or np.isnan(d):\n",
    "        a = 0.5 if np.isnan(a) else a + 0.5\n",
    "        b = 0.5 if np.isnan(b) else b + 0.5\n",
    "        c = 0.5 if np.isnan(c) else c + 0.5\n",
    "        d = 0.5 if np.isnan(d) else d + 0.5\n",
    "\n",
    "    return (a*d)/(b*c)\n",
    "\n",
    "def odds_ratio_lower_ci(OR, a, b, c, d, confidence_level):\n",
    "    if a==0 or np.isnan(a) or b==0 or np.isnan(b) or c==0 or np.isnan(c) or d==0 or np.isnan(d):\n",
    "        a = 0.5 if np.isnan(a) else a + 0.5\n",
    "        b = 0.5 if np.isnan(b) else b + 0.5\n",
    "        c = 0.5 if np.isnan(c) else c + 0.5\n",
    "        d = 0.5 if np.isnan(d) else d + 0.5\n",
    "\n",
    "    return np.exp(np.log(OR) - critical_value_dict[confidence_level]*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "\n",
    "def odds_ratio_upper_ci(OR, a, b, c, d, confidence_level):\n",
    "    if a==0 or np.isnan(a) or b==0 or np.isnan(b) or c==0 or np.isnan(c) or d==0 or np.isnan(d):\n",
    "        a = 0.5 if np.isnan(a) else a + 0.5\n",
    "        b = 0.5 if np.isnan(b) else b + 0.5\n",
    "        c = 0.5 if np.isnan(c) else c + 0.5\n",
    "        d = 0.5 if np.isnan(d) else d + 0.5\n",
    "\n",
    "    return np.exp(np.log(OR) + critical_value_dict[confidence_level]*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "\n",
    "def confusion_matrix_data(Yy, Yn, Ny, Nn):\n",
    "    CM = pd.DataFrame({'label':['Yy','Yn','Ny','Nn', \n",
    "                                'y|Y','n|Y','n|N','y|N',\n",
    "                                'Y|y','N|y','N|n','Y|n',\n",
    "                                'Y','N','y','n',\n",
    "                                'Y*','N*','y*','n*',\n",
    "                                'OR_lci90','OR_lci95','OR_lci99','OR','OR_uci90','OR_uci95','OR_uci99', '1',\n",
    "                                'ACC','ACC-','F1','F1-'], \n",
    "                       'value':[Yy,  Yn,  Ny,  Nn,   \n",
    "                                0 if Yy+Yn==0 else Yy/(Yy+Yn), \n",
    "                                0 if Yy+Yn==0 else Yn/(Yy+Yn), \n",
    "                                0 if Ny+Nn==0 else Nn/(Ny+Nn), \n",
    "                                0 if Ny+Nn==0 else Ny/(Ny+Nn),\n",
    "                                0 if Yy+Ny==0 else Yy/(Yy+Ny), \n",
    "                                0 if Yy+Ny==0 else Ny/(Yy+Ny), \n",
    "                                0 if Yn+Nn==0 else Nn/(Yn+Nn), \n",
    "                                0 if Yn+Nn==0 else Yn/(Yn+Nn),\n",
    "                                Yy+Yn, Ny+Nn, Yy+Ny, Yn+Nn, \n",
    "                                (Yy+Yn)/(Yy+Yn+Ny+Nn), (Ny+Nn)/(Yy+Yn+Ny+Nn), \n",
    "                                (Yy+Ny)/(Yy+Yn+Ny+Nn), (Yn+Nn)/(Yy+Yn+Ny+Nn),\n",
    "                                odds_ratio_lower_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 90), \n",
    "                                odds_ratio_lower_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 95), \n",
    "                                odds_ratio_lower_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 99), \n",
    "                                odds_ratio(Yy, Yn, Ny, Nn), \n",
    "                                odds_ratio_upper_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 90), \n",
    "                                odds_ratio_upper_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 95), \n",
    "                                odds_ratio_upper_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 99), \n",
    "                                1,\n",
    "                                (Yy+Nn)/(Yy+Yn+Ny+Nn), (Yn+Ny)/(Yy+Yn+Ny+Nn),\n",
    "                                0 if Yy==0 or Yy+Yn==0 or Yy+Ny==0 else 2 * ((Yy/(Yy+Yn)) * (Yy/(Yy+Ny))) / ((Yy/(Yy+Yn)) + (Yy/(Yy+Ny))),\n",
    "                                1 if Yy==0 or Yy+Yn==0 or Yy+Ny==0 else 1 - (2 * ((Yy/(Yy+Yn)) * (Yy/(Yy+Ny))) / ((Yy/(Yy+Yn)) + (Yy/(Yy+Ny))))\n",
    "                               ]})\n",
    "\n",
    "\n",
    "    colours = alt.Scale(domain=['Yy','Yn','Ny','Nn', \n",
    "                                'y|Y','n|Y','n|N','y|N',\n",
    "                                'Y|y','N|y','N|n','Y|n',\n",
    "                                'Y','N','y','n',\n",
    "                                'Y*','N*',\n",
    "                                'y*','n*',\n",
    "                                'OR_lci90','OR_lci95','OR_lci99','OR','OR_uci90','OR_uci95','OR_uci99', '1',\n",
    "                                'ACC','ACC-','F1','F1-'], \n",
    "                        range =['snow', 'snow','snow', 'snow',\n",
    "                                'forestgreen','palegreen','powderblue','cadetblue',\n",
    "                                'forestgreen','cadetblue','powderblue','palegreen',\n",
    "                                'goldenrod','gold','goldenrod','gold',\n",
    "                                'goldenrod','gold',\n",
    "                                'goldenrod','gold',\n",
    "                                'dodgerblue','deepskyblue','lightskyblue','blue',\n",
    "                                'dodgerblue','deepskyblue','lightskyblue','darkorange',\n",
    "                                'goldenrod','gold','goldenrod','gold'\n",
    "                               ])\n",
    "    return CM, colours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_v_bar(CM, colours, label_list, sort_order, w_factor, h_factor, sf):\n",
    "    bar = alt.Chart(CM.loc[CM['label'].isin(label_list)]).mark_bar(size=w_factor*sf).encode(\n",
    "        y=alt.Y('sum(value)', stack='normalize', title=None, axis=None),\n",
    "        color=alt.Color('label', scale = colours, legend=None),\n",
    "        order=alt.Order('label', sort=sort_order),\n",
    "        tooltip=['value']\n",
    "    ).properties(width=w_factor*sf, height=h_factor*sf) \n",
    "    \n",
    "    return bar\n",
    "\n",
    "def cf_h_bar(CM, colours, label_list, sort_order, w_factor, h_factor, sf):\n",
    "    bar = alt.Chart(CM.loc[CM['label'].isin(label_list)]).mark_bar(size=h_factor*sf).encode(\n",
    "        x=alt.X('sum(value)', stack='normalize', title=None, axis=None),\n",
    "        color=alt.Color('label', scale = colours, legend=None),\n",
    "        order=alt.Order('label', sort=sort_order),\n",
    "        tooltip=['value']\n",
    "    ).properties(width=w_factor*sf, height=h_factor*sf) \n",
    "    \n",
    "    return bar\n",
    "\n",
    "\n",
    "def cf_text(CM, label, format, font_size, w_factor, dy_factor, sf):\n",
    "    text = alt.Chart(CM.loc[CM['label']==label]).mark_text(fontSize=font_size, color='black').encode(\n",
    "        text=alt.Text('sum(value)', format=format)\n",
    "    ).properties(width=w_factor*sf, height=w_factor*sf) \n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def confusion_matrix_chart(Yy, Yn, Ny, Nn):\n",
    "    \n",
    "    # Scaling factor\n",
    "    sf = 15  \n",
    "    \n",
    "    \n",
    "    # Derive chart data\n",
    "    CM, colours = confusion_matrix_data(Yy, Yn, Ny, Nn)\n",
    "    \n",
    "    \n",
    "    # FIRST ROW\n",
    "\n",
    "    text_Yy = cf_text(CM, label='Yy', format='.0f', font_size=36, \n",
    "                      w_factor=10, dy_factor=5, sf=sf)\n",
    "\n",
    "    bar_Y = cf_v_bar(CM, colours,\n",
    "                     label_list=['n|Y','y|Y'], sort_order='descending', \n",
    "                     w_factor=2, h_factor=10, sf=sf)\n",
    "    \n",
    "    text_Yn = cf_text(CM, label='Yn', format='.0f', font_size=36, \n",
    "                      w_factor=10, dy_factor=5, sf=sf)\n",
    "\n",
    "    # SECOND ROW\n",
    "    \n",
    "    bar_y = cf_h_bar(CM, colours,\n",
    "                     label_list=['Y|y','N|y'], sort_order='ascending', \n",
    "                     w_factor=10, h_factor=2, sf=sf)\n",
    "    \n",
    "    bar_a = cf_v_bar(CM, colours,\n",
    "                     label_list=['ACC','ACC-'], sort_order='ascending', \n",
    "                     w_factor=2, h_factor=2, sf=sf)\n",
    "    \n",
    "    bar_n = cf_h_bar(CM, colours,\n",
    "                     label_list=['N|n','Y|n'], sort_order='ascending', \n",
    "                     w_factor=10, h_factor=2, sf=sf)\n",
    "    \n",
    "    # THIRD ROW\n",
    "    \n",
    "    text_Ny = cf_text(CM, label='Ny', format='.0f', font_size=36, \n",
    "                      w_factor=10, dy_factor=5, sf=sf)\n",
    "\n",
    "    bar_N = cf_v_bar(CM, colours,\n",
    "                     label_list=['n|N','y|N'], sort_order='descending', \n",
    "                     w_factor=2, h_factor=10, sf=sf)\n",
    "    \n",
    "    text_Nn = cf_text(CM, label='Nn', format='.0f', font_size=36, \n",
    "                      w_factor=10, dy_factor=5, sf=sf)\n",
    "\n",
    "    \n",
    "    # FRAMING BARS\n",
    "    \n",
    "    # Left bar\n",
    "    bar_L = cf_v_bar(CM, colours,\n",
    "                     label_list=['Y*','N*'], sort_order='ascending', \n",
    "                     w_factor=2, h_factor=25, sf=sf)\n",
    "    \n",
    "    # Top left corner bar\n",
    "    bar_0 = cf_v_bar(CM, colours,\n",
    "                     label_list=['F1','F1-'], sort_order='ascending', \n",
    "                     w_factor=2, h_factor=2, sf=sf)\n",
    "    \n",
    "    # Top bar\n",
    "    bar_T = cf_h_bar(CM, colours,\n",
    "                     label_list=['y*','n*'], sort_order='descending', \n",
    "                     w_factor=25, h_factor=2, sf=sf)\n",
    "    \n",
    "    # Top right corner text\n",
    "    text_R = cf_text(CM, label='OR', format='.1f', font_size=12, w_factor=2, dy_factor=1, sf=sf)\n",
    "\n",
    "    # Right bar\n",
    "    bar_R = alt.Chart(CM.loc[\n",
    "        CM['label'].isin(['1','OR_lci90','OR_lci95','OR_lci99','OR','OR_uci90','OR_uci95','OR_uci99'])]\n",
    "                     ).mark_circle(opacity=0.8, stroke='black', strokeWidth=1, size=10*sf).encode(\n",
    "        y=alt.Y('value', title=None, axis=None),\n",
    "        color=alt.Color('label', scale = colours, legend=None),\n",
    "        order=alt.Order('label', sort='descending'),\n",
    "        tooltip=['value']\n",
    "    ).properties(width=2*sf, height=25*sf) \n",
    "\n",
    "\n",
    "    # BUILD COMBINED CHART\n",
    "    \n",
    "    return (bar_0 | bar_T | text_R) & ( \n",
    "        bar_L | ( ( (text_Yy) | bar_Y | text_Yn) & (bar_y | bar_a | bar_n) & (text_Ny | bar_N | text_Nn) ) \n",
    "     | bar_R )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-7beed3d37c36486bbfae4cd7b9c71d92\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7beed3d37c36486bbfae4cd7b9c71d92\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7beed3d37c36486bbfae4cd7b9c71d92\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"data\": {\"name\": \"data-56b8a82d2cd9614ef88536bf572ff56a\"}, \"mark\": {\"type\": \"bar\", \"size\": 30}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"ascending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"y\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"value\", \"stack\": \"normalize\", \"title\": null}}, \"height\": 30, \"width\": 30}, {\"data\": {\"name\": \"data-1e5ec6f336ff0d3b5c1a833d88fe840a\"}, \"mark\": {\"type\": \"bar\", \"size\": 30}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"descending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"x\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"value\", \"stack\": \"normalize\", \"title\": null}}, \"height\": 30, \"width\": 375}, {\"data\": {\"name\": \"data-948f8d122a558ff300fed9387a477cb9\"}, \"mark\": {\"type\": \"text\", \"color\": \"black\", \"fontSize\": 12}, \"encoding\": {\"text\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"field\": \"value\", \"format\": \".1f\"}}, \"height\": 30, \"width\": 30}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-f73dd7a201d98db3dd36e39986c45f74\"}, \"mark\": {\"type\": \"bar\", \"size\": 30}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"ascending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"y\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"value\", \"stack\": \"normalize\", \"title\": null}}, \"height\": 375, \"width\": 30}, {\"vconcat\": [{\"hconcat\": [{\"data\": {\"name\": \"data-82e9ee7b58371a5e1d9b2a84e413ee6a\"}, \"mark\": {\"type\": \"text\", \"color\": \"black\", \"fontSize\": 36}, \"encoding\": {\"text\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"field\": \"value\", \"format\": \".0f\"}}, \"height\": 150, \"width\": 150}, {\"data\": {\"name\": \"data-d7da23a0577838c5fdf85c6bdf487d9b\"}, \"mark\": {\"type\": \"bar\", \"size\": 30}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"descending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"y\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"value\", \"stack\": \"normalize\", \"title\": null}}, \"height\": 150, \"width\": 30}, {\"data\": {\"name\": \"data-998ab66e57b91d8ca179ec9310ffa0c8\"}, \"mark\": {\"type\": \"text\", \"color\": \"black\", \"fontSize\": 36}, \"encoding\": {\"text\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"field\": \"value\", \"format\": \".0f\"}}, \"height\": 150, \"width\": 150}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-38f7c1359df6a2d6ce13da7b25aef3f3\"}, \"mark\": {\"type\": \"bar\", \"size\": 30}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"ascending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"x\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"value\", \"stack\": \"normalize\", \"title\": null}}, \"height\": 30, \"width\": 150}, {\"data\": {\"name\": \"data-5a59b761fc4dabc880c7579631932f50\"}, \"mark\": {\"type\": \"bar\", \"size\": 30}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"ascending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"y\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"value\", \"stack\": \"normalize\", \"title\": null}}, \"height\": 30, \"width\": 30}, {\"data\": {\"name\": \"data-3b3c24b21e359b52d406844f2b4e2988\"}, \"mark\": {\"type\": \"bar\", \"size\": 30}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"ascending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"x\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"value\", \"stack\": \"normalize\", \"title\": null}}, \"height\": 30, \"width\": 150}]}, {\"hconcat\": [{\"data\": {\"name\": \"data-b069f5f55f11b8e7b621e9d636836cc0\"}, \"mark\": {\"type\": \"text\", \"color\": \"black\", \"fontSize\": 36}, \"encoding\": {\"text\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"field\": \"value\", \"format\": \".0f\"}}, \"height\": 150, \"width\": 150}, {\"data\": {\"name\": \"data-c108cbeba57a588c29436c49907f1a6c\"}, \"mark\": {\"type\": \"bar\", \"size\": 30}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"descending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"y\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"value\", \"stack\": \"normalize\", \"title\": null}}, \"height\": 150, \"width\": 30}, {\"data\": {\"name\": \"data-7e58dd3ffc972c75c09917fed47005e2\"}, \"mark\": {\"type\": \"text\", \"color\": \"black\", \"fontSize\": 36}, \"encoding\": {\"text\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"field\": \"value\", \"format\": \".0f\"}}, \"height\": 150, \"width\": 150}]}]}, {\"data\": {\"name\": \"data-97ef7e84497824c4a0e519bc24671eac\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.8, \"size\": 150, \"stroke\": \"black\", \"strokeWidth\": 1}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"label\", \"legend\": null, \"scale\": {\"domain\": [\"Yy\", \"Yn\", \"Ny\", \"Nn\", \"y|Y\", \"n|Y\", \"n|N\", \"y|N\", \"Y|y\", \"N|y\", \"N|n\", \"Y|n\", \"Y\", \"N\", \"y\", \"n\", \"Y*\", \"N*\", \"y*\", \"n*\", \"OR_lci90\", \"OR_lci95\", \"OR_lci99\", \"OR\", \"OR_uci90\", \"OR_uci95\", \"OR_uci99\", \"1\", \"ACC\", \"ACC-\", \"F1\", \"F1-\"], \"range\": [\"snow\", \"snow\", \"snow\", \"snow\", \"forestgreen\", \"palegreen\", \"powderblue\", \"cadetblue\", \"forestgreen\", \"cadetblue\", \"powderblue\", \"palegreen\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"blue\", \"dodgerblue\", \"deepskyblue\", \"lightskyblue\", \"darkorange\", \"goldenrod\", \"gold\", \"goldenrod\", \"gold\"]}}, \"order\": {\"type\": \"nominal\", \"field\": \"label\", \"sort\": \"descending\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"value\"}], \"y\": {\"type\": \"quantitative\", \"axis\": null, \"field\": \"value\", \"title\": null}}, \"height\": 375, \"width\": 30}]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-56b8a82d2cd9614ef88536bf572ff56a\": [{\"label\": \"F1\", \"value\": 0.003979701074428082}, {\"label\": \"F1-\", \"value\": 0.9960202989255719}], \"data-1e5ec6f336ff0d3b5c1a833d88fe840a\": [{\"label\": \"y*\", \"value\": 0.999018509891055}, {\"label\": \"n*\", \"value\": 0.0009814901089449542}], \"data-948f8d122a558ff300fed9387a477cb9\": [{\"label\": \"OR\", \"value\": 0.00011607066266902045}], \"data-f73dd7a201d98db3dd36e39986c45f74\": [{\"label\": \"Y*\", \"value\": 0.002921355361238532}, {\"label\": \"N*\", \"value\": 0.9970786446387615}], \"data-82e9ee7b58371a5e1d9b2a84e413ee6a\": [{\"label\": \"Yy\", \"value\": 22253.0}], \"data-d7da23a0577838c5fdf85c6bdf487d9b\": [{\"label\": \"y|Y\", \"value\": 0.6824608212960407}, {\"label\": \"n|Y\", \"value\": 0.31753917870395926}], \"data-998ab66e57b91d8ca179ec9310ffa0c8\": [{\"label\": \"Yn\", \"value\": 10354.0}], \"data-38f7c1359df6a2d6ce13da7b25aef3f3\": [{\"label\": \"Y|y\", \"value\": 0.001995669308815768}, {\"label\": \"N|y\", \"value\": 0.9980043306911842}], \"data-5a59b761fc4dabc880c7579631932f50\": [{\"label\": \"ACC\", \"value\": 0.0020475559059633026}, {\"label\": \"ACC-\", \"value\": 0.9979524440940367}], \"data-3b3c24b21e359b52d406844f2b4e2988\": [{\"label\": \"N|n\", \"value\": 0.05486079415791876}, {\"label\": \"Y|n\", \"value\": 0.9451392058420812}], \"data-b069f5f55f11b8e7b621e9d636836cc0\": [{\"label\": \"Ny\", \"value\": 11128392.0}], \"data-c108cbeba57a588c29436c49907f1a6c\": [{\"label\": \"n|N\", \"value\": 5.400308904857789e-05}, {\"label\": \"y|N\", \"value\": 0.9999459969109514}], \"data-7e58dd3ffc972c75c09917fed47005e2\": [{\"label\": \"Nn\", \"value\": 601.0}], \"data-97ef7e84497824c4a0e519bc24671eac\": [{\"label\": \"OR_lci90\", \"value\": 0.00010825760266824135}, {\"label\": \"OR_lci95\", \"value\": 0.00010679556640392201}, {\"label\": \"OR_lci99\", \"value\": 0.00010401882246052389}, {\"label\": \"OR\", \"value\": 0.00011607066266902045}, {\"label\": \"OR_uci90\", \"value\": 0.000124447599063431}, {\"label\": \"OR_uci95\", \"value\": 0.00012615129247472908}, {\"label\": \"OR_uci99\", \"value\": 0.00012951885450864835}, {\"label\": \"1\", \"value\": 1.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yy, Yn, Ny, Nn = confusion_matrix.get_matrix()\n",
    "confusion_matrix_chart(Yy, Yn, Ny, Nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

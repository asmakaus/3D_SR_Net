{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from medpy import metric\n",
    "\n",
    "\n",
    "def assert_shape(test, reference):\n",
    "\n",
    "    assert test.shape == reference.shape, \"Shape mismatch: {} and {}\".format(\n",
    "        test.shape, reference.shape)\n",
    "\n",
    "\n",
    "class ConfusionMatrix:\n",
    "\n",
    "    def __init__(self, test=None, reference=None):\n",
    "\n",
    "        self.tp = None\n",
    "        self.fp = None\n",
    "        self.tn = None\n",
    "        self.fn = None\n",
    "        self.size = None\n",
    "        self.reference_empty = None\n",
    "        self.reference_full = None\n",
    "        self.test_empty = None\n",
    "        self.test_full = None\n",
    "        self.set_reference(reference)\n",
    "        self.set_test(test)\n",
    "\n",
    "    def set_test(self, test):\n",
    "\n",
    "        self.test = test\n",
    "        self.reset()\n",
    "\n",
    "    def set_reference(self, reference):\n",
    "\n",
    "        self.reference = reference\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.tp = None\n",
    "        self.fp = None\n",
    "        self.tn = None\n",
    "        self.fn = None\n",
    "        self.size = None\n",
    "        self.test_empty = None\n",
    "        self.test_full = None\n",
    "        self.reference_empty = None\n",
    "        self.reference_full = None\n",
    "\n",
    "    def compute(self):\n",
    "\n",
    "        if self.test is None or self.reference is None:\n",
    "            raise ValueError(\"'test' and 'reference' must both be set to compute confusion matrix.\")\n",
    "\n",
    "        assert_shape(self.test, self.reference)\n",
    "\n",
    "        self.tp = int(((self.test != 0) * (self.reference != 0)).sum())\n",
    "        self.fp = int(((self.test != 0) * (self.reference == 0)).sum())\n",
    "        self.tn = int(((self.test == 0) * (self.reference == 0)).sum())\n",
    "        self.fn = int(((self.test == 0) * (self.reference != 0)).sum())\n",
    "        self.size = int(np.prod(self.reference.shape, dtype=np.int64))\n",
    "        self.test_empty = not np.any(self.test)\n",
    "        self.test_full = np.all(self.test)\n",
    "        self.reference_empty = not np.any(self.reference)\n",
    "        self.reference_full = np.all(self.reference)\n",
    "\n",
    "    def get_matrix(self):\n",
    "\n",
    "        for entry in (self.tp, self.fp, self.tn, self.fn):\n",
    "            if entry is None:\n",
    "                self.compute()\n",
    "                break\n",
    "\n",
    "        return self.tp, self.fp, self.tn, self.fn\n",
    "\n",
    "    def get_size(self):\n",
    "\n",
    "        if self.size is None:\n",
    "            self.compute()\n",
    "        return self.size\n",
    "\n",
    "    def get_existence(self):\n",
    "\n",
    "        for case in (self.test_empty, self.test_full, self.reference_empty, self.reference_full):\n",
    "            if case is None:\n",
    "                self.compute()\n",
    "                break\n",
    "\n",
    "        return self.test_empty, self.test_full, self.reference_empty, self.reference_full\n",
    "\n",
    "\n",
    "def dice(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"2TP / (2TP + FP + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty and reference_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(2 * tp / (2 * tp + fp + fn))\n",
    "\n",
    "\n",
    "def jaccard(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TP / (TP + FP + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty and reference_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(tp / (tp + fp + fn))\n",
    "\n",
    "\n",
    "def precision(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TP / (TP + FP)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    return float(tp / (tp + fp))\n",
    "\n",
    "\n",
    "def sensitivity(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TP / (TP + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if reference_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(tp / (tp + fn))\n",
    "\n",
    "\n",
    "def recall(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TP / (TP + FN)\"\"\"\n",
    "\n",
    "    return sensitivity(test, reference, confusion_matrix, nan_for_nonexisting, **kwargs)\n",
    "\n",
    "\n",
    "def specificity(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TN / (TN + FP)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(tn / (tn + fp))\n",
    "\n",
    "\n",
    "def accuracy(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"(TP + TN) / (TP + FP + FN + TN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return float((tp + tn) / (tp + fp + tn + fn))\n",
    "\n",
    "\n",
    "def fscore(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, beta=1., **kwargs):\n",
    "    \"\"\"(1 + b^2) * TP / ((1 + b^2) * TP + b^2 * FN + FP)\"\"\"\n",
    "\n",
    "    precision_ = precision(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "    recall_ = recall(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "    return (1 + beta*beta) * precision_ * recall_ /\\\n",
    "        ((beta*beta * precision_) + recall_)\n",
    "\n",
    "\n",
    "def false_positive_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"FP / (FP + TN)\"\"\"\n",
    "\n",
    "    return 1 - specificity(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def false_omission_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"FN / (TN + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    return float(fn / (fn + tn))\n",
    "\n",
    "\n",
    "def false_negative_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"FN / (TP + FN)\"\"\"\n",
    "\n",
    "    return 1 - sensitivity(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def true_negative_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TN / (TN + FP)\"\"\"\n",
    "\n",
    "    return specificity(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def false_discovery_rate(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"FP / (TP + FP)\"\"\"\n",
    "\n",
    "    return 1 - precision(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def negative_predictive_value(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"TN / (TN + FN)\"\"\"\n",
    "\n",
    "    return 1 - false_omission_rate(test, reference, confusion_matrix, nan_for_nonexisting)\n",
    "\n",
    "\n",
    "def total_positives_test(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"TP + FP\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return tp + fp\n",
    "\n",
    "\n",
    "def total_negatives_test(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"TN + FN\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return tn + fn\n",
    "\n",
    "\n",
    "def total_positives_reference(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"TP + FN\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return tp + fn\n",
    "\n",
    "\n",
    "def total_negatives_reference(test=None, reference=None, confusion_matrix=None, **kwargs):\n",
    "    \"\"\"TN + FP\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "\n",
    "    return tn + fp\n",
    "\n",
    "\n",
    "def hausdorff_distance(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, voxel_spacing=None, connectivity=1, **kwargs):\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty or test_full or reference_empty or reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test, reference = confusion_matrix.test, confusion_matrix.reference\n",
    "\n",
    "    return metric.hd(test, reference, voxel_spacing, connectivity)\n",
    "\n",
    "\n",
    "def hausdorff_distance_95(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, voxel_spacing=None, connectivity=1, **kwargs):\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty or test_full or reference_empty or reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test, reference = confusion_matrix.test, confusion_matrix.reference\n",
    "\n",
    "    return metric.hd95(test, reference, voxel_spacing, connectivity)\n",
    "\n",
    "\n",
    "def avg_surface_distance(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, voxel_spacing=None, connectivity=1, **kwargs):\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty or test_full or reference_empty or reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test, reference = confusion_matrix.test, confusion_matrix.reference\n",
    "\n",
    "    return metric.asd(test, reference, voxel_spacing, connectivity)\n",
    "\n",
    "\n",
    "def avg_surface_distance_symmetric(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, voxel_spacing=None, connectivity=1, **kwargs):\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty or test_full or reference_empty or reference_full:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    test, reference = confusion_matrix.test, confusion_matrix.reference\n",
    "\n",
    "    return metric.assd(test, reference, voxel_spacing, connectivity)\n",
    "\n",
    "\n",
    "ALL_METRICS = {\n",
    "    \"False Positive Rate\": false_positive_rate,\n",
    "    \"Dice\": dice,\n",
    "    \"Jaccard\": jaccard,\n",
    "    \"Hausdorff Distance\": hausdorff_distance,\n",
    "    \"Hausdorff Distance 95\": hausdorff_distance_95,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"Avg. Symmetric Surface Distance\": avg_surface_distance_symmetric,\n",
    "    \"Avg. Surface Distance\": avg_surface_distance,\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"False Omission Rate\": false_omission_rate,\n",
    "    \"Negative Predictive Value\": negative_predictive_value,\n",
    "    \"False Negative Rate\": false_negative_rate,\n",
    "    \"True Negative Rate\": true_negative_rate,\n",
    "    \"False Discovery Rate\": false_discovery_rate,\n",
    "    \"Total Positives Test\": total_positives_test,\n",
    "    \"Total Negatives Test\": total_negatives_test,\n",
    "    \"Total Positives Reference\": total_positives_reference,\n",
    "    \"total Negatives Reference\": total_negatives_reference\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import torch\n",
    "import argparse\n",
    "import skimage, os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import nibabel as nib\n",
    "import csv\n",
    "\n",
    "BASE_IMG_PATH=os.path.join('/','home','asma','Documents','GPU','final_results01','Task02_Heart','Task02_Heart')\n",
    "gt=sorted(glob(os.path.join(BASE_IMG_PATH,'gt_3dsrn3','*.nii')))\n",
    "out=sorted(glob(os.path.join(BASE_IMG_PATH,'resnnUNet_seg_output3','*.nii')))\n",
    "\n",
    "f_metrics = [\n",
    "        \"False Positive Rate\",\n",
    "        \"Dice\",\n",
    "        \"Jaccard\",\n",
    "        \"Hausdorff Distance\",\n",
    "        \"Hausdorff Distance 95\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"Avg. Symmetric Surface Distance\",\n",
    "        \"Avg. Surface Distance\",\n",
    "        \"Accuracy\",\n",
    "        \"False Omission Rate\",\n",
    "        \"Negative Predictive Value\",\n",
    "        \"False Negative Rate\",\n",
    "        \"True Negative Rate\",\n",
    "        \"False Discovery Rate\",\n",
    "        \"Total Positives Test\",\n",
    "        \"Total Negatives Test\",\n",
    "        \"Total Positives Reference\",\n",
    "        \"total Negatives Reference\"]\n",
    "with open(os.path.join(BASE_IMG_PATH,'my_metrics_3DSRNet_test3.csv'), 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(f_metrics)\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    for i in range(len(gt)):\n",
    "        test = nib.load(out[i]).get_fdata()\n",
    "        reference = nib.load(gt[i]).get_fdata()\n",
    "        test = np.atleast_1d(test.astype(np.bool))\n",
    "        reference = np.atleast_1d(reference.astype(np.bool))\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "        tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    \n",
    "        my_metrics = {\n",
    "            false_positive_rate(test, reference,confusion_matrix),\n",
    "            dice(test, reference,confusion_matrix),\n",
    "            jaccard(test, reference,confusion_matrix),\n",
    "            hausdorff_distance(test, reference,confusion_matrix),\n",
    "            hausdorff_distance_95(test, reference,confusion_matrix),\n",
    "            precision(test, reference,confusion_matrix),\n",
    "            recall(test, reference,confusion_matrix),\n",
    "            avg_surface_distance_symmetric(test, reference,confusion_matrix),\n",
    "            avg_surface_distance(test, reference,confusion_matrix),\n",
    "            accuracy(test, reference,confusion_matrix),\n",
    "            false_omission_rate(test, reference,confusion_matrix),\n",
    "            negative_predictive_value(test, reference,confusion_matrix),\n",
    "            false_negative_rate(test, reference,confusion_matrix),\n",
    "            true_negative_rate(test, reference,confusion_matrix),\n",
    "            false_discovery_rate(test, reference,confusion_matrix),\n",
    "            total_positives_test(test, reference,confusion_matrix),\n",
    "            total_negatives_test(test, reference,confusion_matrix),\n",
    "            total_positives_reference(test, reference,confusion_matrix),\n",
    "            total_negatives_reference(test, reference,confusion_matrix)\n",
    "            }\n",
    "        writer.writerow(my_metrics)\n",
    "#        writer.writerow({tp,fp,tn,fn})\n",
    "        prec = float(tp / (tp + fn))\n",
    "        rec = float(tp / (tp + fp))\n",
    "        writer.writerow({prec,rec})\n",
    "#        print(metric.binary.hd(test, reference))\n",
    "        \n",
    "#    metrics = np.hstack((metrics,my_metrics))\n",
    "\n",
    "#    print(confusion_matrix.get_matrix())\n",
    "#    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "#    print(float(tp / (tp + fn)))\n",
    "        print(metric.hd95(test,reference))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = ((test != 0) * (reference != 0)).sum()\n",
    "tn = ((test == 0) * (reference == 0)).sum()\n",
    "fp = ((test != 0) * (reference == 0)).sum()\n",
    "fn = ((test == 0) * (reference != 0)).sum()\n",
    "\n",
    "print(tp)\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_metrics = {\n",
    "#        \"False Positive Rate\": false_positive_rate(test, reference),\n",
    "#        \"Dice\": dice(test, reference),\n",
    "#        \"Jaccard\": jaccard(test, reference),\n",
    "#        \"Hausdorff Distance\": hausdorff_distance(test, reference),\n",
    "#        \"Hausdorff Distance 95\": hausdorff_distance_95(test, reference),\n",
    "#        \"Precision\": precision(test, reference),\n",
    "#        \"Recall\": recall(test, reference),\n",
    "#        \"Avg. Symmetric Surface Distance\": avg_surface_distance_symmetric(test, reference),\n",
    "#        \"Avg. Surface Distance\": avg_surface_distance(test, reference),\n",
    "#        \"Accuracy\": accuracy(test, reference),\n",
    "#        \"False Omission Rate\": false_omission_rate(test, reference),\n",
    "#        \"Negative Predictive Value\": negative_predictive_value(test, reference),\n",
    "#        \"False Negative Rate\": false_negative_rate(test, reference),\n",
    "#        \"True Negative Rate\": true_negative_rate(test, reference),\n",
    "#        \"False Discovery Rate\": false_discovery_rate(test, reference),\n",
    "#        \"Total Positives Test\": total_positives_test(test, reference),\n",
    "#        \"Total Negatives Test\": total_negatives_test(test, reference),\n",
    "#        \"Total Positives Reference\": total_positives_reference(test, reference),\n",
    "#        \"total Negatives Reference\": total_negatives_reference(test, reference)\n",
    "#    } \n",
    "#my_metrics = np.array(my_metrics)\n",
    "#metrics = np.array([\n",
    "#        \"False Positive Rate\",\"Dice\",\n",
    "#        \"Jaccard\",\n",
    "#        \"Hausdorff Distance\",\n",
    "#        \"Hausdorff Distance 95\",\n",
    "#        \"Precision\",\n",
    "#        \"Recall\",\n",
    "#        \"Avg. Symmetric Surface Distance\",\n",
    "#        \"Avg. Surface Distance\",\n",
    "#        \"Accuracy\",\n",
    "#        \"False Omission Rate\",\n",
    "#        \"Negative Predictive Value\",\n",
    "#        \"False Negative Rate\",\n",
    "#        \"True Negative Rate\",\n",
    "#        \"False Discovery Rate\",\n",
    "#        \"Total Positives Test\",\n",
    "#        \"Total Negatives Test\",\n",
    "#        \"Total Positives Reference\",\n",
    "#        \"total Negatives Reference\"])    \n",
    "\n",
    "#f_metrics = np.hstack((my_metrics,metrics))\n",
    "\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "f_metrics = [\n",
    "        \"False Positive Rate\",\"Dice\",\n",
    "        \"Jaccard\",\n",
    "        \"Hausdorff Distance\",\n",
    "        \"Hausdorff Distance 95\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"Avg. Symmetric Surface Distance\",\n",
    "        \"Avg. Surface Distance\",\n",
    "        \"Accuracy\",\n",
    "        \"False Omission Rate\",\n",
    "        \"Negative Predictive Value\",\n",
    "        \"False Negative Rate\",\n",
    "        \"True Negative Rate\",\n",
    "        \"False Discovery Rate\",\n",
    "        \"Total Positives Test\",\n",
    "        \"Total Negatives Test\",\n",
    "        \"Total Positives Reference\",\n",
    "        \"total Negatives Reference\"]\n",
    "with open(os.path.join(BASE_IMG_PATH,'my_metrics_3DSRNet_test1.csv'), 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(f_metrics)\n",
    "    writer.writerows(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "critical_value_dict = {70:1.04, 75:1.15, 80:1.28, 85:1.44, 90:1.64 , 95:1.96 , 98:2.33 , 99:2.58}\n",
    "\n",
    "def odds_ratio(a, b, c, d):\n",
    "    if a==0 or np.isnan(a) or b==0 or np.isnan(b) or c==0 or np.isnan(c) or d==0 or np.isnan(d):\n",
    "        a = 0.5 if np.isnan(a) else a + 0.5\n",
    "        b = 0.5 if np.isnan(b) else b + 0.5\n",
    "        c = 0.5 if np.isnan(c) else c + 0.5\n",
    "        d = 0.5 if np.isnan(d) else d + 0.5\n",
    "\n",
    "    return (a*d)/(b*c)\n",
    "\n",
    "def odds_ratio_lower_ci(OR, a, b, c, d, confidence_level):\n",
    "    if a==0 or np.isnan(a) or b==0 or np.isnan(b) or c==0 or np.isnan(c) or d==0 or np.isnan(d):\n",
    "        a = 0.5 if np.isnan(a) else a + 0.5\n",
    "        b = 0.5 if np.isnan(b) else b + 0.5\n",
    "        c = 0.5 if np.isnan(c) else c + 0.5\n",
    "        d = 0.5 if np.isnan(d) else d + 0.5\n",
    "\n",
    "    return np.exp(np.log(OR) - critical_value_dict[confidence_level]*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "\n",
    "def odds_ratio_upper_ci(OR, a, b, c, d, confidence_level):\n",
    "    if a==0 or np.isnan(a) or b==0 or np.isnan(b) or c==0 or np.isnan(c) or d==0 or np.isnan(d):\n",
    "        a = 0.5 if np.isnan(a) else a + 0.5\n",
    "        b = 0.5 if np.isnan(b) else b + 0.5\n",
    "        c = 0.5 if np.isnan(c) else c + 0.5\n",
    "        d = 0.5 if np.isnan(d) else d + 0.5\n",
    "\n",
    "    return np.exp(np.log(OR) + critical_value_dict[confidence_level]*np.sqrt(1/a + 1/b + 1/c + 1/d))\n",
    "\n",
    "def confusion_matrix_data(Yy, Yn, Ny, Nn):\n",
    "    CM = pd.DataFrame({'label':['Yy','Yn','Ny','Nn', \n",
    "                                'y|Y','n|Y','n|N','y|N',\n",
    "                                'Y|y','N|y','N|n','Y|n',\n",
    "                                'Y','N','y','n',\n",
    "                                'Y*','N*','y*','n*',\n",
    "                                'OR_lci90','OR_lci95','OR_lci99','OR','OR_uci90','OR_uci95','OR_uci99', '1',\n",
    "                                'ACC','ACC-','F1','F1-'], \n",
    "                       'value':[Yy,  Yn,  Ny,  Nn,   \n",
    "                                0 if Yy+Yn==0 else Yy/(Yy+Yn), \n",
    "                                0 if Yy+Yn==0 else Yn/(Yy+Yn), \n",
    "                                0 if Ny+Nn==0 else Nn/(Ny+Nn), \n",
    "                                0 if Ny+Nn==0 else Ny/(Ny+Nn),\n",
    "                                0 if Yy+Ny==0 else Yy/(Yy+Ny), \n",
    "                                0 if Yy+Ny==0 else Ny/(Yy+Ny), \n",
    "                                0 if Yn+Nn==0 else Nn/(Yn+Nn), \n",
    "                                0 if Yn+Nn==0 else Yn/(Yn+Nn),\n",
    "                                Yy+Yn, Ny+Nn, Yy+Ny, Yn+Nn, \n",
    "                                (Yy+Yn)/(Yy+Yn+Ny+Nn), (Ny+Nn)/(Yy+Yn+Ny+Nn), \n",
    "                                (Yy+Ny)/(Yy+Yn+Ny+Nn), (Yn+Nn)/(Yy+Yn+Ny+Nn),\n",
    "                                odds_ratio_lower_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 90), \n",
    "                                odds_ratio_lower_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 95), \n",
    "                                odds_ratio_lower_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 99), \n",
    "                                odds_ratio(Yy, Yn, Ny, Nn), \n",
    "                                odds_ratio_upper_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 90), \n",
    "                                odds_ratio_upper_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 95), \n",
    "                                odds_ratio_upper_ci(odds_ratio(Yy, Yn, Ny, Nn), Yy, Yn, Ny, Nn, 99), \n",
    "                                1,\n",
    "                                (Yy+Nn)/(Yy+Yn+Ny+Nn), (Yn+Ny)/(Yy+Yn+Ny+Nn),\n",
    "                                0 if Yy==0 or Yy+Yn==0 or Yy+Ny==0 else 2 * ((Yy/(Yy+Yn)) * (Yy/(Yy+Ny))) / ((Yy/(Yy+Yn)) + (Yy/(Yy+Ny))),\n",
    "                                1 if Yy==0 or Yy+Yn==0 or Yy+Ny==0 else 1 - (2 * ((Yy/(Yy+Yn)) * (Yy/(Yy+Ny))) / ((Yy/(Yy+Yn)) + (Yy/(Yy+Ny))))\n",
    "                               ]})\n",
    "\n",
    "\n",
    "    colours = alt.Scale(domain=['Yy','Yn','Ny','Nn', \n",
    "                                'y|Y','n|Y','n|N','y|N',\n",
    "                                'Y|y','N|y','N|n','Y|n',\n",
    "                                'Y','N','y','n',\n",
    "                                'Y*','N*',\n",
    "                                'y*','n*',\n",
    "                                'OR_lci90','OR_lci95','OR_lci99','OR','OR_uci90','OR_uci95','OR_uci99', '1',\n",
    "                                'ACC','ACC-','F1','F1-'], \n",
    "                        range =['snow', 'snow','snow', 'snow',\n",
    "                                'forestgreen','palegreen','powderblue','cadetblue',\n",
    "                                'forestgreen','cadetblue','powderblue','palegreen',\n",
    "                                'goldenrod','gold','goldenrod','gold',\n",
    "                                'goldenrod','gold',\n",
    "                                'goldenrod','gold',\n",
    "                                'dodgerblue','deepskyblue','lightskyblue','blue',\n",
    "                                'dodgerblue','deepskyblue','lightskyblue','darkorange',\n",
    "                                'goldenrod','gold','goldenrod','gold'\n",
    "                               ])\n",
    "    return CM, colours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_v_bar(CM, colours, label_list, sort_order, w_factor, h_factor, sf):\n",
    "    bar = alt.Chart(CM.loc[CM['label'].isin(label_list)]).mark_bar(size=w_factor*sf).encode(\n",
    "        y=alt.Y('sum(value)', stack='normalize', title=None, axis=None),\n",
    "        color=alt.Color('label', scale = colours, legend=None),\n",
    "        order=alt.Order('label', sort=sort_order),\n",
    "        tooltip=['value']\n",
    "    ).properties(width=w_factor*sf, height=h_factor*sf) \n",
    "    \n",
    "    return bar\n",
    "\n",
    "def cf_h_bar(CM, colours, label_list, sort_order, w_factor, h_factor, sf):\n",
    "    bar = alt.Chart(CM.loc[CM['label'].isin(label_list)]).mark_bar(size=h_factor*sf).encode(\n",
    "        x=alt.X('sum(value)', stack='normalize', title=None, axis=None),\n",
    "        color=alt.Color('label', scale = colours, legend=None),\n",
    "        order=alt.Order('label', sort=sort_order),\n",
    "        tooltip=['value']\n",
    "    ).properties(width=w_factor*sf, height=h_factor*sf) \n",
    "    \n",
    "    return bar\n",
    "\n",
    "\n",
    "def cf_text(CM, label, format, font_size, w_factor, dy_factor, sf):\n",
    "    text = alt.Chart(CM.loc[CM['label']==label]).mark_text(fontSize=font_size, color='black').encode(\n",
    "        text=alt.Text('sum(value)', format=format)\n",
    "    ).properties(width=w_factor*sf, height=w_factor*sf) \n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def confusion_matrix_chart(Yy, Yn, Ny, Nn):\n",
    "    \n",
    "    # Scaling factor\n",
    "    sf = 15  \n",
    "    \n",
    "    \n",
    "    # Derive chart data\n",
    "    CM, colours = confusion_matrix_data(Yy, Yn, Ny, Nn)\n",
    "    \n",
    "    \n",
    "    # FIRST ROW\n",
    "\n",
    "    text_Yy = cf_text(CM, label='Yy', format='.0f', font_size=36, \n",
    "                      w_factor=10, dy_factor=5, sf=sf)\n",
    "\n",
    "    bar_Y = cf_v_bar(CM, colours,\n",
    "                     label_list=['n|Y','y|Y'], sort_order='descending', \n",
    "                     w_factor=2, h_factor=10, sf=sf)\n",
    "    \n",
    "    text_Yn = cf_text(CM, label='Yn', format='.0f', font_size=36, \n",
    "                      w_factor=10, dy_factor=5, sf=sf)\n",
    "\n",
    "    # SECOND ROW\n",
    "    \n",
    "    bar_y = cf_h_bar(CM, colours,\n",
    "                     label_list=['Y|y','N|y'], sort_order='ascending', \n",
    "                     w_factor=10, h_factor=2, sf=sf)\n",
    "    \n",
    "    bar_a = cf_v_bar(CM, colours,\n",
    "                     label_list=['ACC','ACC-'], sort_order='ascending', \n",
    "                     w_factor=2, h_factor=2, sf=sf)\n",
    "    \n",
    "    bar_n = cf_h_bar(CM, colours,\n",
    "                     label_list=['N|n','Y|n'], sort_order='ascending', \n",
    "                     w_factor=10, h_factor=2, sf=sf)\n",
    "    \n",
    "    # THIRD ROW\n",
    "    \n",
    "    text_Ny = cf_text(CM, label='Ny', format='.0f', font_size=36, \n",
    "                      w_factor=10, dy_factor=5, sf=sf)\n",
    "\n",
    "    bar_N = cf_v_bar(CM, colours,\n",
    "                     label_list=['n|N','y|N'], sort_order='descending', \n",
    "                     w_factor=2, h_factor=10, sf=sf)\n",
    "    \n",
    "    text_Nn = cf_text(CM, label='Nn', format='.0f', font_size=36, \n",
    "                      w_factor=10, dy_factor=5, sf=sf)\n",
    "\n",
    "    \n",
    "    # FRAMING BARS\n",
    "    \n",
    "    # Left bar\n",
    "    bar_L = cf_v_bar(CM, colours,\n",
    "                     label_list=['Y*','N*'], sort_order='ascending', \n",
    "                     w_factor=2, h_factor=25, sf=sf)\n",
    "    \n",
    "    # Top left corner bar\n",
    "    bar_0 = cf_v_bar(CM, colours,\n",
    "                     label_list=['F1','F1-'], sort_order='ascending', \n",
    "                     w_factor=2, h_factor=2, sf=sf)\n",
    "    \n",
    "    # Top bar\n",
    "    bar_T = cf_h_bar(CM, colours,\n",
    "                     label_list=['y*','n*'], sort_order='descending', \n",
    "                     w_factor=25, h_factor=2, sf=sf)\n",
    "    \n",
    "    # Top right corner text\n",
    "    text_R = cf_text(CM, label='OR', format='.1f', font_size=12, w_factor=2, dy_factor=1, sf=sf)\n",
    "\n",
    "    # Right bar\n",
    "    bar_R = alt.Chart(CM.loc[\n",
    "        CM['label'].isin(['1','OR_lci90','OR_lci95','OR_lci99','OR','OR_uci90','OR_uci95','OR_uci99'])]\n",
    "                     ).mark_circle(opacity=0.8, stroke='black', strokeWidth=1, size=10*sf).encode(\n",
    "        y=alt.Y('value', title=None, axis=None),\n",
    "        color=alt.Color('label', scale = colours, legend=None),\n",
    "        order=alt.Order('label', sort='descending'),\n",
    "        tooltip=['value']\n",
    "    ).properties(width=2*sf, height=25*sf) \n",
    "\n",
    "\n",
    "    # BUILD COMBINED CHART\n",
    "    \n",
    "    return (bar_0 | bar_T | text_R) & ( \n",
    "        bar_L | ( ( (text_Yy) | bar_Y | text_Yn) & (bar_y | bar_a | bar_n) & (text_Ny | bar_N | text_Nn) ) \n",
    "     | bar_R )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yy, Yn, Ny, Nn = confusion_matrix.get_matrix()\n",
    "confusion_matrix_chart(Yy, Yn, Ny, Nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
